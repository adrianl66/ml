nzv <- nearZeroVar(trainset, saveMetrics=TRUE)
mytrainset <- trainset[,nzv$nzv==FALSE]
mytrainset <- mytrainset[c(-1)] #remove the id column as it doesn't add info for the ML algorithms
df <- whatis(mytrainset) #Use the YaleTookkit library to find features which has a large percentage of missing values
df <- mutate(df_mytrainset,NARatio = missing / (missing + distinct.values))
df <- mutate(mytrainset,NARatio = missing / (missing + distinct.values))
df
dim(df)
dim(mytrainset)
?whatis
dim(mytrainset)
dim(df)
df <- filter(df, missing != 0) #select fields which do not have missing data
dim(df)
df
dim(df)
df <- whatis(mytrainset) #Use the YaleTookkit library to remove fields with a large number of NA
df <- filter(df, missing == 0) #select fields which do not have missing data
dim(df)
df
dim(dfa)
dim(df)
myvector <- df$variable.name
df_train_clean <- mytrainset[,myvector]
dim(mytrainset)
dim(df_train_clean)
set.seed(80)
intrain = createDataPartition(trainset$classe,p=0.6,list=FALSE)
training = trainset[intrain,]
testing = trainset[-intrain,]
dim(training)
dim(testing)
?nearZeroVar
trainRawFile <- read.csv('./train.csv', sep=',', stringsAsFactors = FALSE, strip.white = TRUE)
testRawFile <- read.csv('./test.csv', sep=',', stringsAsFactors = FALSE,strip.white = TRUE)
# Create a training and a testing set from the downloaded trainset
#
set.seed(80)
intrain = createDataPartition(trainRawFile$classe,p=0.6,list=FALSE)
trainSet = trainRawFile[intrain,]
testSet = trainRawFile[-intrain,]
dim(trainSet)
dim(testSet)
nzv <- nearZeroVar(trainSet, saveMetrics=TRUE)
myTrainSet <- trainset[,nzv$nzv==FALSE]
myTrainSet <- myTrainSet[c(-1)] #remove the id column as it doesn't add info for the ML algorithms
#Use the YaleTookkit library to remove fields with a large number of NA
#
df <- whatis(myTrainSet)
dim(df)
dim(myTrainSet)
nzv <- nearZeroVar(trainSet, saveMetrics=TRUE)
myTrainSet <- trainSet[,nzv$nzv==FALSE]
myTrainSet <- myTrainSet[c(-1)] #remove the id column as it doesn't add info for the ML algorithms
dim(myTrainSet)
nzv <- nearZeroVar(trainSet, saveMetrics=TRUE)
myTrainSet <- trainSet[,nzv$nzv==FALSE]
nzv <- nearZeroVar(testSet, saveMetrics=TRUE)
myTrainSet <- testSet[,nzv$nzv==FALSE]
nzv <- nearZeroVar(trainSet, saveMetrics=TRUE)
myTrainSet <- trainSet[,nzv$nzv==FALSE]
nzv <- nearZeroVar(testSet, saveMetrics=TRUE)
myTestSet <- testSet[,nzv$nzv==FALSE]
dim(myTrainSet)
dim(myTestSet)
set.seed(80)
intrain = createDataPartition(trainRawFile$classe,p=0.6,list=FALSE)
trainSet = trainRawFile[intrain,]
testSet = trainRawFile[-intrain,]
dim(trainSet)
dim(testSet)
# Clean the data
# Remove near to zero variance variables as they do not have prediction value
nzv <- nearZeroVar(trainSet, saveMetrics=TRUE)
myTrainSet <- trainSet[,nzv$nzv==FALSE]
nzv <- nearZeroVar(testSet, saveMetrics=TRUE)
myTestSet <- testSet[,nzv$nzv==FALSE]
dim(myTrainSet)
dim(myTestSet)
str(myTrainSet)
df <- whatis(myTrainSet)
df <- filter(df, missing == 0) #select fields which do not have missing data
myvector <- df$variable.name
df_train_clean <- mytrainset[,myvector]
df_train_clean <- myTrainSet[,myvector]
dim(df_train_clean)
df_train_clean <- myTrainSet[c(-1)] #remove the id column as it doesn't add info for the ML algorithms
dim(df_train_clean)
dfTrainCleaned <- myTrainSet[,myvector]
dfTrainCleaned <- dfTrainCleaned[c(-1)] #remove the id column as it doesn't add info for the ML algorithms
dim(dfTrainCleaned)
names(dfTrainCleaned)
dim(myTestSet)
T <- myTestSet[colnames(dfTrainCleaned)]
dim(T)
dfTrainCleaned <- myTrainSet[,myvector]
dfTrainCleaned <- dfTrainCleaned[c(-1)] #remove the id column as it doesn't add info for the ML algorithms
dfTestCleaned <- myTestSet[colnames(dfTrainCleaned)] # Ensure ony same variables are in the Cleaned Test Set
dim(dfTrainCleaned)
dim(dfTestCleaned)
names(dfTrainCleaned)
names(dfTestCleaned)
str(dfTrainedCleaned)
str(dfTrainCleaned)
str(dfTestCleaned)
trainRawFile <- read.csv('./train.csv', sep=',', stringsAsFactors = FALSE, strip.white = TRUE)
testRawFile <- read.csv('./test.csv', sep=',', stringsAsFactors = FALSE,strip.white = TRUE)
# Create a training and a testing set from the downloaded trainset
#
set.seed(80)
intrain = createDataPartition(trainRawFile$classe,p=0.6,list=FALSE)
trainSet = trainRawFile[intrain,]
testSet = trainRawFile[-intrain,]
dim(trainSet)
dim(testSet)
# Clean the data
# Remove near to zero variance variables as they do not have prediction value
nzv <- nearZeroVar(trainSet, saveMetrics=TRUE)
myTrainSet <- trainSet[,nzv$nzv==FALSE]
nzv <- nearZeroVar(testSet, saveMetrics=TRUE)
myTestSet <- testSet[,nzv$nzv==FALSE]
dim(myTrainSet)
dim(myTestSet)
#Use the YaleTookkit library to remove fields with a large number of NA
#
df <- whatis(myTrainSet)
df <- filter(df, missing == 0) #select fields which do not have missing data
myvector <- df$variable.name
dfTrainCleaned <- myTrainSet[,myvector]
dfTrainCleaned <- dfTrainCleaned[c(-1)] #remove the id column as it doesn't add info for the ML algorithms
dfTestCleaned <- myTestSet[colnames(dfTrainCleaned)] # Ensure ony same variables are in the Cleaned Test Set
dim(dfTrainCleaned)
dim(dfTestCleaned)
str(dfTrainCleaned)
whatis(dfTrainCleaned)
trainURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testURL  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
if (!file.exists("./train.csv")) {
download.file(trainURL,"./train.csv",method='auto')
}
if (!file.exists("./test.csv")) {
download.file(testURL,"./test.csv",method='auto')
}
trainRawFile <- read.csv('./train.csv', sep=',', stringsAsFactors = FALSE, strip.white = TRUE)
testRawFile <- read.csv('./test.csv', sep=',', stringsAsFactors = FALSE,strip.white = TRUE)
# Create a training and a testing set from the downloaded trainset
#
set.seed(80)
intrain = createDataPartition(trainRawFile$classe,p=0.6,list=FALSE)
trainSet = trainRawFile[intrain,]
testSet = trainRawFile[-intrain,]
dim(trainSet)
dim(testSet)
# Clean the data
# Remove near to zero variance variables as they do not have prediction value
nzv <- nearZeroVar(trainSet, saveMetrics=TRUE)
myTrainSet <- trainSet[,nzv$nzv==FALSE]
nzv <- nearZeroVar(testSet, saveMetrics=TRUE)
myTestSet <- testSet[,nzv$nzv==FALSE]
dim(myTrainSet)
dim(myTestSet)
df <- whatis(myTrainSet)
df
df <- filter(df, missing == 0)
df
myvector <- df$variable.name
dim(myTrainSet)
dfTrainCleaned <- myTrainSet[,myvector]
dim(dfTrainCleaned)
whatis(dfTrainCleaned)
set.seed(80)
intrain = createDataPartition(trainRawFile$classe,p=0.6,list=FALSE)
trainSet = trainRawFile[intrain,]
testSet = trainRawFile[-intrain,]
dim(trainSet)
dim(testSet)
# Clean the data
# Remove near to zero variance variables as they do not have prediction value
nzv <- nearZeroVar(trainSet, saveMetrics=TRUE)
myTrainSet <- trainSet[,nzv$nzv==FALSE]
nzv <- nearZeroVar(testSet, saveMetrics=TRUE)
myTestSet <- testSet[,nzv$nzv==FALSE]
dim(myTrainSet)
dim(myTestSet)
df <- whatis(myTrainSet)
dim(df)
df
df <- filter(df, missing == 0)
dim(df)
df
myvector <- df$variable.name
dfTrainCleaned <- myTrainSet[,myvector]
dim(dfTrainCleaned)
names(dfTrainCleaned)
whatis(dfTrainCleaned)
?nearZeroVar
set.seed(80)
intrain = createDataPartition(trainRawFile$classe,p=0.6,list=FALSE)
trainSet = trainRawFile[intrain,]
testSet = trainRawFile[-intrain,]
dim(trainSet)
dim(testSet)
# Clean the data
# Remove near to zero variance variables as they do not have prediction value
nzv <- nearZeroVar(trainSet, saveMetrics=TRUE)
myTrainSet <- trainSet[,nzv$nzv==FALSE]
nzv <- nearZeroVar(testSet, saveMetrics=TRUE)
myTestSet <- testSet[,nzv$nzv==FALSE]
dim(myTrainSet)
dim(myTestSet)
View(myTrainSet)
set.seed(80)
intrain = createDataPartition(trainRawFile$classe,p=0.6,list=FALSE)
trainSet = trainRawFile[intrain,]
testSet = trainRawFile[-intrain,]
dim(trainSet)
dim(testSet)
df <- whatis(trainSet)
dim(df)
df
df <- filter(df, missing == 0) #select fields which do not have missing data
df
myvector <- df$variable.name
dfTrainCleaned <- myTrainSet[,myvector]
myvector <- df$variable.name
dfTrainCleaned <- trainSet[,myvector]
dfTrainCleaned
df
df <- whatis(trainSet)
df <- filter(df, missing == 0) #select fields which do not have missing data
myvector <- df$variable.name
dfTrainCleaned <- trainSet[,myvector]
dim(dfTrainCleaned)
whatis(dfTrainCleaned)
trainRawFile <- read.csv('./train.csv', sep=',', stringsAsFactors = FALSE, strip.white = TRUE)
testRawFile <- read.csv('./test.csv', sep=',', stringsAsFactors = FALSE,strip.white = TRUE)
# Create a training and a testing set from the downloaded trainset
#
set.seed(80)
intrain = createDataPartition(trainRawFile$classe,p=0.6,list=FALSE)
trainSet = trainRawFile[intrain,]
testSet = trainRawFile[-intrain,]
dim(trainSet)
dim(testSet)
# Clean the data
# Remove near to zero variance variables as they do not have prediction value
nzv <- nearZeroVar(trainSet, saveMetrics=TRUE)
myTrainSet <- trainSet[,nzv$nzv==FALSE]
nzv <- nearZeroVar(testSet, saveMetrics=TRUE)
myTestSet <- testSet[,nzv$nzv==FALSE]
dim(myTrainSet)
dim(myTestSet)
#Use the YaleTookkit library to remove fields with a large number of NA
#
df <- whatis(myTrainSet)
df <- filter(df, missing == 0) #select fields which do not have missing data
myvector <- df$variable.name
dfTrainCleaned <- myTrainSet[,myvector]
dfTrainCleaned <- dfTrainCleaned[c(-1)] #remove the id column as it doesn't add info for the ML algorithms
dfTestCleaned <- myTestSet[colnames(dfTrainCleaned)] # Ensure ony same variables are in the Cleaned Test Set
dim(dfTrainCleaned)
dim(dfTestCleaned)
set.seed(12345)
modFitB1 <- randomForest(classe ~ ., data=dfTrainCleaned)
predictionB1 <- predict(modFitB1, dfTestCleaned, type = "class")
cmrf <- confusionMatrix(predictionB1, dfTestCleaned$classe)
cmrf
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))
inTrain <- createDataPartition(training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ]
myTesting <- training[-inTrain, ]
dim(myTraining); dim(myTesting)
nzv <- nearZeroVar(myTraining, saveMetrics=TRUE)
myTraining <- myTraining[,nzv$nzv==FALSE]
nzv<- nearZeroVar(myTesting,saveMetrics=TRUE)
myTesting <- myTesting[,nzv$nzv==FALSE]
whatis(myTraining)
myTraining <- myTraining[c(-1)]
trainingV3 <- myTraining
for(i in 1:length(myTraining)) {
if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .7) {
for(j in 1:length(trainingV3)) {
if( length( grep(names(myTraining[i]), names(trainingV3)[j]) ) == 1)  {
trainingV3 <- trainingV3[ , -j]
}
}
}
}
myTraining <- trainingV3
rm(trainingV3)
clean1 <- colnames(myTraining)
clean2 <- colnames(myTraining[, -58])  # remove the classe column
myTesting <- myTesting[clean1]         # allow only variables in myTesting that are also in myTraining
testing <- testing[clean2]             # allow only variables in testing that are also in myTraining
dim(myTesting)
whatis(myTesting)
dim(testing)
for (i in 1:length(testing) ) {
for(j in 1:length(myTraining)) {
if( length( grep(names(myTraining[i]), names(testing)[j]) ) == 1)  {
class(testing[j]) <- class(myTraining[i])
}
}
}
# To get the same class between testing and myTraining
testing <- rbind(myTraining[2, -58] , testing)
testing <- testing[-1,]
set.seed(12345)
modFitB1 <- randomForest(classe ~ ., data=myTraining)
predictionB1 <- predict(modFitB1, myTesting, type = "class")
cmrf <- confusionMatrix(predictionB1, myTesting$classe)
cmrf
plot(modFitB1)
plot(cmrf$table, col = cmtree$byClass, main = paste("Random Forest Confusion Matrix: Accuracy =", round(cmrf$overall['Accuracy'], 4)))
plot(cmrf$table, col = cmtree$byClass, main = paste("Random Forest Confusion Matrix: Accuracy =", round(cmrf$overall['Accuracy'], 4)))
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
answers = rep("A", 20)
pml_write_files(answers)
getwd()
pml_write_files(predictionB1)
dim(predictionB1)
predictionB1
predictionB1 <- predict(modFitB1, testRawFile, type = "class")
predictionB2 <- predict(modFitB1, testing, type = "class")
predictionB2
pml_write_files(predictionB2)
predictionB2
str(predictionB2)
dim(trainSet)
length(trainSet)
nrow(trainSet)
na_test = sapply(trainSet,function(x) {sum(is.na(x))})
na_test
table)na_test
table(na_test)
str(na_test)
set.seed(80)
intrain = createDataPartition(trainRawFile$classe,p=0.6,list=FALSE)
trainSet = trainRawFile[intrain,]
testSet = trainRawFile[-intrain,]
dim(trainSet)
dim(testSet)
# Clean the data
# Remove near to zero variance variables as they do not have prediction value
nzv <- nearZeroVar(trainSet, saveMetrics=TRUE)
myTrainSet <- trainSet[,nzv$nzv==FALSE]
nzv <- nearZeroVar(testSet, saveMetrics=TRUE)
myTestSet <- testSet[,nzv$nzv==FALSE]
dim(myTrainSet)
dim(myTestSet)
#Use the YaleTookkit library to remove fields with a large number of NA
#
df <- whatis(myTrainSet)
df <- filter(df, missing == 0) #select fields which do not have missing data
myvector <- df$variable.name
dfTrainCleaned <- myTrainSet[,myvector]
dim(dfTrainCleaned)
na_test <- sapply(dfTrainCleaned, function(x) {sum(is.na(x))})
na_test
table(na_test)
bad_columns = names(na_test[na_test==11524])
training = dfTrainCleaned[, !names(dfTrainCleaned) %in% bad_columns]
str(training)
whatis(training)
set.seed(80)
intrain = createDataPartition(trainRawFile$classe,p=0.6,list=FALSE)
trainSet = trainRawFile[intrain,]
testSet = trainRawFile[-intrain,]
dim(trainSet)
dim(testSet)
# Clean the data
# Remove near to zero variance variables as they do not have prediction value
nzv <- nearZeroVar(trainSet, saveMetrics=TRUE)
myTrainSet <- trainSet[,nzv$nzv==FALSE]
nzv <- nearZeroVar(testSet, saveMetrics=TRUE)
myTestSet <- testSet[,nzv$nzv==FALSE]
dim(myTrainSet)
dim(myTestSet)
#Use the YaleTookkit library to remove fields with a large number of NA
#
df <- whatis(myTrainSet)
df <- filter(df, missing == 0) #select fields which do not have missing data
myvector <- df$variable.name
dfTrainCleaned <- myTrainSet[,myvector]
dim(dfTrainCleaned)
na_test <- sapply(dfTrainCleaned, function(x) {sum(is.na(x))})
table(na_test)
dirty_cols = names(na_test[na_test==11524])
dfTrainCleaned = dfTrainCleaned[, !names(dfTrainCleaned) %in% dirty_cols]
dfTestCleaned <- myTestSet[colnames(dfTrainCleaned)] # Ensure ony same variables are in the Cleaned Test Set
dim(dfTrainCleaned)
dim(dfTestCleaned)
model <- randomForest(classe ~ ., data=dfTrainCleaned)
whatis(dfTrainCleaned)
str(dfTrainCleaned)
set.seed(80)
intrain = createDataPartition(trainRawFile$classe,p=0.6,list=FALSE)
trainSet = trainRawFile[intrain,]
testSet = trainRawFile[-intrain,]
dim(trainSet)
dim(testSet)
# Clean the data
# Remove near to zero variance variables as they do not have prediction value
nzv <- nearZeroVar(trainSet, saveMetrics=TRUE)
myTrainSet <- trainSet[,nzv$nzv==FALSE]
nzv <- nearZeroVar(testSet, saveMetrics=TRUE)
myTestSet <- testSet[,nzv$nzv==FALSE]
dim(myTrainSet)
dim(myTestSet)
#Use the YaleTookkit library to remove fields with a large number of NA
#
df <- whatis(myTrainSet)
df <- filter(df, missing == 0) #select fields which do not have missing data
myvector <- df$variable.name
dfTrainCleaned <- myTrainSet[,myvector]
dim(dfTrainCleaned)
View(dfTrainCleaned)
na_test <- sapply(dfTrainCleaned, function(x) {sum(is.na(x))})
table(na_test)
dirty_cols = names(na_test[na_test==11524])
dfTrainCleaned = dfTrainCleaned[, !names(dfTrainCleaned) %in% dirty_cols]
dim(dfTrainCleaned)
View(dfTrainCleaned)
set.seed(80)
intrain = createDataPartition(trainRawFile$classe,p=0.6,list=FALSE)
trainSet = trainRawFile[intrain,]
testSet = trainRawFile[-intrain,]
dim(trainSet)
dim(testSet)
# Clean the data
# Remove near to zero variance variables as they do not have prediction value
nzv <- nearZeroVar(trainSet, saveMetrics=TRUE)
myTrainSet <- trainSet[,nzv$nzv==FALSE]
nzv <- nearZeroVar(testSet, saveMetrics=TRUE)
myTestSet <- testSet[,nzv$nzv==FALSE]
dim(myTrainSet)
dim(myTestSet)
View(myTrainSet)
View(myTestSet)
myTrainSet <- myTrainSet[,c(1:7)]
myTestSet <- myTestSet[,c(1:7)]
dim(myTrainSet)
dim(myTestSet)
set.seed(80)
intrain = createDataPartition(trainRawFile$classe,p=0.6,list=FALSE)
trainSet = trainRawFile[intrain,]
testSet = trainRawFile[-intrain,]
dim(trainSet)
dim(testSet)
# Clean the data
# Remove near to zero variance variables as they do not have prediction value
nzv <- nearZeroVar(trainSet, saveMetrics=TRUE)
myTrainSet <- trainSet[,nzv$nzv==FALSE]
nzv <- nearZeroVar(testSet, saveMetrics=TRUE)
myTestSet <- testSet[,nzv$nzv==FALSE]
dim(myTrainSet)
dim(myTestSet)
# Remove the first 7 columns as they ID, subject names and timestamp info which are not related to movement
myTrainSet <- myTrainSet[,-c(1:7)]
myTestSet <- myTestSet[,-c(1:7)]
dim(myTrainSet)
dim(myTestSet)
dfTrainCleaned <- myTrainSet
na_test <- sapply(dfTrainCleaned, function(x) {sum(is.na(x))})
table(na_test)
dirty_cols = names(na_test[na_test==11524])
dfTrainCleaned = dfTrainCleaned[, !names(dfTrainCleaned) %in% dirty_cols]
dfTestCleaned <- myTestSet[colnames(dfTrainCleaned)]
dim(dfTrainCleaned)
dim(dfTestCleaned)
model <- randomForest(classe ~ ., data=dfTrainCleaned)
model = train(classe~.,method="rf",data=dfTrainCleaned)
mean(predict(model, dfTestCleaned) == dfTestCleaned$classe) * 100
library(parallel)
library(doparallel)
library(doParallel)
install.packages(doParallel)
library(doParallel)
install.packages("doParallel")
library(doParallel)
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)
c1
cl
ctrl <- trainControl(classProbs=TRUE,
savePredictions=TRUE,
allowParallel=TRUE,method="cv",number=3)
system.time(trainingModel <- train(classe ~ ., data=DTrainCleaned)
)
system.time(trainingModel <- train(classe ~ ., data=DfTrainCleaned))
system.time(trainingModel <- train(classe ~ ., data=dfTrainCleaned))
model
library(R.utils)
library(RCurl)
library(ggplot2)
library(dplyr)
library(knitr)
library(caret)
library(parallel)
library(doParallel)
getwd()
setwd("C:/Users/Adrian/Desktop/Git\ Repository/Coursera/machine\ learning/ml")
getwd()
